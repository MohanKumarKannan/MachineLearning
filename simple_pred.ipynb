{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running For Input Field:   Close\n",
      "running for: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) 43.87 43.2\n",
      "Mean squared error: 14.19\n",
      "Variance score: 0.84\n",
      "running for: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 44.11 43.2\n",
      "Mean squared error: 2.35\n",
      "Variance score: 0.97\n",
      "running for: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False) 44.12 43.2\n",
      "Mean squared error: 2.35\n",
      "Variance score: 0.97\n",
      "running for: TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False)\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False) 44.06 43.2\n",
      "Mean squared error: 2.29\n",
      "Variance score: 0.97\n",
      "Running For Input Field:   High\n",
      "running for: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) 44.45 47.25\n",
      "Mean squared error: 10.30\n",
      "Variance score: 0.89\n",
      "running for: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 43.76 47.25\n",
      "Mean squared error: 1.12\n",
      "Variance score: 0.99\n",
      "running for: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False) 43.77 47.25\n",
      "Mean squared error: 1.12\n",
      "Variance score: 0.99\n",
      "running for: TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False)\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False) 44.21 47.25\n",
      "Mean squared error: 1.07\n",
      "Variance score: 0.99\n",
      "Running For Input Field:   Low\n",
      "running for: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) 43.21 42.9\n",
      "Mean squared error: 11.24\n",
      "Variance score: 0.87\n",
      "running for: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 41.28 42.9\n",
      "Mean squared error: 1.17\n",
      "Variance score: 0.99\n",
      "running for: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False) 41.29 42.9\n",
      "Mean squared error: 1.17\n",
      "Variance score: 0.99\n",
      "running for: TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False)\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False) 41.91 42.9\n",
      "Mean squared error: 1.02\n",
      "Variance score: 0.99\n",
      "Running For Input Field:   Open\n",
      "running for: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) 43.94 46.85\n",
      "Mean squared error: 6.56\n",
      "Variance score: 0.93\n",
      "running for: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 42.85 46.85\n",
      "Mean squared error: 0.35\n",
      "Variance score: 1.00\n",
      "running for: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False) 42.86 46.85\n",
      "Mean squared error: 0.35\n",
      "Variance score: 1.00\n",
      "running for: TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False)\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False) 43.51 46.85\n",
      "Mean squared error: 0.28\n",
      "Variance score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta, TH\n",
    "from sklearn import preprocessing,svm,linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#data = pd.read_csv('Input/tv18_5years.csv', header=0,index_col=False)\n",
    "\n",
    "#filepath = 'Input/tv18_all.csv'\n",
    "filepath = 'Input/tv18_0904.csv'\n",
    "dollar_file ='Input/USD_INR Historical Data - Copy.csv' \n",
    "\n",
    "\n",
    "def define_input(filepath):\n",
    "    data = pd.read_csv(filepath, header=0,index_col=False)\n",
    "    data = data[['Date','Open','High','Low','Close','Volume']]\n",
    "    data.fillna(value=-99999, inplace=True)\n",
    "    data=data[(data[\"Volume\"] > 0) & (data[\"Close\"] > 0.0001)]\n",
    "    dd = pd.read_csv(dollar_file, header=0,index_col=False,delimiter ='\\t')\n",
    "    dd['Date'] =dd[dd.Date >=min(data.Date)]\n",
    "    dd = dd[['Date','Price']]\n",
    "    data=data.join(dd.set_index('Date'), on='Date')\n",
    "    data = data.reset_index()\n",
    "    data = data[['Date','Open','High','Low','Close','Volume',\"Price\"]]\n",
    "    return data\n",
    "\n",
    "def calc_last_thursday(year_mon):\n",
    "\n",
    "    input_date = pd.to_datetime(year_mon + ('-01'))\n",
    "    cmon = input_date.month\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        t = input_date + relativedelta(weekday=TH(i))\n",
    "        if t.month != cmon:\n",
    "            # since t is exceeded we need last one  which we can get by subtracting -2 since it is already a Thursday.\n",
    "            t = t + relativedelta(weekday=TH(-2))\n",
    "            break\n",
    "    return t.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def build_split_data(data,input_field):\n",
    "    all_dates = data[['Date']].loc[1:]\n",
    "    date_month = all_dates['Date'].str[0:7].drop_duplicates()\n",
    "    option_end_Date = []\n",
    "    for i in date_month:    \n",
    "        option_end_Date.append(calc_last_thursday(i))   \n",
    "    \n",
    "    l=[]\n",
    "    cnt = len(data)\n",
    "    cp = cnt-1\n",
    "    for i in range(1,cnt):\n",
    "        p = i-1\n",
    "        if (data[input_field].loc[p] != -99999.000000) or (data[input_field].loc[p] != \"null\"):   \n",
    "            oed = 1 if (str(data['Date'].loc[i])) in option_end_Date else 0     \n",
    "            prefix = data['Date'].loc[i],data[input_field].loc[i]\n",
    "            suffix= data['Volume'].loc[p],0,data['Price'].loc[i]    \n",
    "            if input_field == 'Close':\n",
    "                middle=data['Open'].loc[p],data['High'].loc[p],data['Low'].loc[p]\n",
    "            elif input_field == 'High':\n",
    "                middle = data['Open'].loc[p],data['Close'].loc[p],data['Low'].loc[p]\n",
    "            elif input_field == 'Low':\n",
    "                middle= data['Open'].loc[p],data['Close'].loc[p],data['High'].loc[p]\n",
    "            elif input_field == 'Open':\n",
    "                middle= data['Close'].loc[p],data['High'].loc[p],data['Low'].loc[p]\n",
    "            k= prefix + middle + suffix\n",
    "            l.append(k)        \n",
    "\n",
    "    prefix = '2099-12-31',data[input_field].loc[cp]\n",
    "    suffix= data['Volume'].loc[cp],0,data['Price'].loc[cp]    \n",
    "    if input_field =='Close':\n",
    "        labels= ['Date',input_field,'Open','High','Low','Volume',\"Option EndDt Ind\",\"Price\"]\n",
    "        middle=  data['Open'].loc[cp],data['High'].loc[cp],data['Low'].loc[cp]\n",
    "    elif input_field == 'High':\n",
    "        labels= ['Date',input_field,'Open','Close','Low','Volume',\"Option EndDt Ind\",\"Price\"]\n",
    "        middle=  data['Open'].loc[cp],data['Close'].loc[cp],data['Low'].loc[cp]\n",
    "    elif input_field == 'Low':\n",
    "        labels= ['Date',input_field,'Open','Close','High','Volume',\"Option EndDt Ind\",\"Price\"]\n",
    "        middle= data['Open'].loc[cp],data['Close'].loc[cp],data['High'].loc[cp]\n",
    "    elif input_field == 'Open':\n",
    "        labels= ['Date',input_field,'Close','High','Low','Volume',\"Option EndDt Ind\",\"Price\"]\n",
    "        middle= data['Close'].loc[cp],data['High'].loc[cp],data['Low'].loc[cp]\n",
    "    k = prefix + middle +suffix\n",
    "    l.append(k)\n",
    "    df2 = pd.DataFrame.from_records(l, columns=labels)\n",
    "    #df3=y_label.join(df2.set_index('Date'), on='Date')    \n",
    "\n",
    "    split_data = np.array(df2.drop(['Date'], 1))\n",
    "    return split_data\n",
    "\n",
    "def cross_validate(split_data):\n",
    "    n=len(split_data)\n",
    "    train_start = 0\n",
    "    train_end = int(np.floor(0.9*n))\n",
    "    test_start = train_end\n",
    "    test_end = n\n",
    "    data_train = split_data[np.arange(train_start, train_end), :]\n",
    "    data_test = split_data[np.arange(test_start, test_end), :]\n",
    "    y_train = data_train[:,0]\n",
    "    y_test = data_test[:,0]\n",
    "\n",
    "    X_train =data_train[:,1:]\n",
    "    X_test =data_test[:,1:]\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "def run_classifier(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    classifiers = [svm.SVR(),\n",
    "                   linear_model.LinearRegression(),\n",
    "                   linear_model.BayesianRidge(),\n",
    "                   #linear_model.ARDRegression(),\n",
    "                   linear_model.TheilSenRegressor()\n",
    "                  ]\n",
    "\n",
    "    last = len(y_test)-1\n",
    "    for i in classifiers:\n",
    "        print(\"running for: %s\" % i )\n",
    "        regression = i\n",
    "        regression.fit(X_train, y_train)\n",
    "        predicted = regression.predict(X_test)\n",
    "        #for i in range(len(y_test)-1,len(y_test)-2,-1):\n",
    "        #    print(np.round(predicted[i],2),np.round(y_test[i],2))\n",
    "        print(i,np.round(predicted[last],2),np.round(y_test[last],2))\n",
    "        print(\"Mean squared error: %.2f\" % np.mean((predicted - y_test) ** 2))\n",
    "        print('Variance score: %.2f' % regression.score(X_test, y_test))\n",
    "\n",
    "# Training and test data preparation\n",
    "#df3=df1.join(df2.set_index('Date'), on='Date')\n",
    "\n",
    "def predict_value_for(input_field):\n",
    "    data = define_input(filepath)\n",
    "    print('Running For Input Field:  ', input_field)\n",
    "    split_data = build_split_data(data,input_field)\n",
    "    X_train,y_train,X_test,y_test = cross_validate(split_data)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    run_classifier(X_train,y_train,X_test,y_test)\n",
    "    \n",
    "if __name__ =='__main__' :\n",
    "    values = ['Close','High','Low','Open']\n",
    "    #values = ['Close']    \n",
    "    for v in values:        \n",
    "        predict_value_for(v)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
